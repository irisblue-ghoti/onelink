input {
  # 从日志文件收集日志
  file {
    path => "/logs/**/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    type => "log"
  }
  
  # 从TCP收集日志
  tcp {
    port => 5000
    codec => "json"
    type => "tcp"
  }
  
  # 从UDP收集日志
  udp {
    port => 5000
    codec => "json"
    type => "udp"
  }
}

filter {
  if [type] == "log" {
    # 解析JSON格式的日志
    json {
      source => "message"
    }
    
    # 添加日志来源标识
    mutate {
      add_field => { "source" => "file" }
    }
  }
  
  # 解析时间字段
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # 如果存在trace_id，则添加到字段中
  if [trace_id] {
    mutate {
      add_field => { "[@metadata][trace_id]" => "%{trace_id}" }
    }
  }
  
  # 添加服务名称字段
  if [service] {
    mutate {
      add_field => { "[@metadata][service]" => "%{service}" }
    }
  }
}

output {
  # 输出到Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[@metadata][service]}-%{+YYYY.MM.dd}"
    document_type => "%{[@metadata][type]}"
  }
  
  # 调试输出，用于验证日志解析是否正确
  # 生产环境可以删除或注释此部分
  stdout {
    codec => rubydebug
  }
} 